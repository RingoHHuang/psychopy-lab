{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "168c6ba0",
   "metadata": {},
   "source": [
    "# Lab 4 - Red Light, Green Light, Approaching the Doll\n",
    "\n",
    "Last week, we built the Red Light, Green Light game, which is essentially a \"Squid Game\" themed Go/No-Go task.\n",
    "\n",
    "To follow along today, please download the Lab 4 folder from CCLE. We will be starting with the **redlight_greenlight_approach_class_demo.psyexp** file, and modifying it as we work through the worksheet. Let's run this program and take a look at what we have so far...\n",
    "\n",
    "Today, we will add some embellishments to make this game more interesting, both in terms of the research question that we may want to ask and in terms of making it more gamified and engaging for the participant. I'm calling this version \"Red Light, Green Light, Approaching the Doll\" for now (but please let me know if you can come up with a more creative name!).\n",
    "\n",
    "#### Red Light, Green Light, Approaching the Doll\n",
    "In this version of the Red Light, Green Light game, participants take a \"step\" closer to the finish line every time they make a Hit (i.e., pressing space when the back of the doll is facing them). If participants take a \"step\" closer when the doll turns around (i.e., False Alarming or pressing space when the doll is facing them), they need to take a few \"steps\" back. To give the sense of progress, the doll will appear larger with each \"step\". Once the participant reaches the target number of Hits, the session finishes.\n",
    "\n",
    "#### To-Do List:\n",
    "- Set a number of \"steps\" to get to the finish line\n",
    "- With each \"step\", make the doll appear larger\n",
    "- Introduce rules for each Hit and False Alarm (e.g., each Hit is 1 step closer, but each FA is 2 steps back)\n",
    "- Enable experimenter to specify parameters at the start of the experiment\n",
    "- Fun embellishments (if time)! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6256898",
   "metadata": {},
   "source": [
    "## The code so far\n",
    "Last week, we went over a few approaches to creating the sequence of images to be presented in each trial. However, there's a more programmatic approach to building these sequences. The advantage in the following code is that you can create a sequence of X length just by specifying the number of go trials (`num_0s`) and the number of no-go trials (`num_1s`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd956c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Programmatic approach\n",
    "num_0s = 20\n",
    "num_1s = 10\n",
    "\n",
    "sequence = []\n",
    "for i in range(num_0s):\n",
    "    sequence.append(0)\n",
    "for i in range(num_1s):\n",
    "    sequence.append(1)\n",
    "    \n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4bcd6",
   "metadata": {},
   "source": [
    "With this approach, it's necessary to randomly shuffle the image sequence. You'll need to import the random module to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f518c79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Randomize\n",
    "import random\n",
    "random.seed(101)   # seeding with \"subject id\"\n",
    "random.shuffle(sequence)\n",
    "\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d834e14",
   "metadata": {},
   "source": [
    "#### A quick note on (pseudo)-randomization:\n",
    "Randomization can be a tricky topic, so I want to point out some \"best practice\". Usually, it's a good idea to **seed** the randomization functions with a number that is unique to your participant (e.g., the subject ID). If using the random module in Python, this isn't absolutely necessary because they use the OS time as the default seed. However, it is necessary in Matlab and JS, and there are cases where studies were run without proper trial randomization because they forgot to seed the random functions.\n",
    "\n",
    "Additionally, seeding is also useful when you want to replicate the \"pseudorandom\" sequence. For example, you might want to use the same seed across multiple sessions if you want the same \"pseudorandom\" sequence to be given to the same participant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7369c",
   "metadata": {},
   "source": [
    " ## Make the doll image larger or smaller with each trial\n",
    "The goal with this is to give a sense of movement when the doll appears larger (approaching) and when the doll appears smaller (retreating). Moreover, this gives the participant a sense of progress towards their target \"distance\".\n",
    " \n",
    " ##### Steps:\n",
    " \n",
    "\n",
    "1. **In Begin Experiment tab**, create a `distance_goal` variable where we specify the number of hits or \"steps\" needed to pass the game. Also create a `distance_counter` variable that keeps track of the number of hits.\n",
    "2. Create the `min_w`, `min_h`, `max_w`, `max_h` variables so that we can specify the starting and ending dimensions of the image. \n",
    "3. Calculate `inc_w` and `inc_h` using the previous variables. These are the increments (in image dimensions) to be added each time a hit is recorded (i.e., this is like how \"large\" of a step to take). Calculated as: `inc_w = (max_w - min_w)/distance_goal`.\n",
    "4. **In Begin Routine tab**, Update the `im_w` and `im_h` variables, which are the *current* dimensions of the doll image. These variables are calculated as: `im_w = min_w + distance_counter*inc_w`.\n",
    "5. **In End Routine tab**, Here, we need to update the distance counter by 1 if a hit occurred.\n",
    "6. We also want to check if `distance_counter == distance_goal`. When this conditional is True, terminate the trial early using this: `trials.finished = True`.\n",
    "6. **In doll_im Properties**, In the Layout tab, find the \"Size\" field and enter `[im_w, im_h]`. Make sure to change the field to set every repeat!\n",
    "\n",
    "Now test the code and see if the doll gets bigger!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993594e8",
   "metadata": {},
   "source": [
    "## Reward and Penalty\n",
    "Our research objective is to shift our participant's response criterion by manipulating the reward/penalty outcomes of Hits and False Alarms. Reward is operationalized by pairing Hits with a number of steps forward, and penalty is operationalized by pairing False Alarms with a number of steps backward.\n",
    "\n",
    "We want to include several different reward/penalty conditions. For the first condition, a Hit moves the subject 1 step forward and a False Alarm moves the subject 1 step back. This is essentially our \"control\" or \"baseline\" condition.\n",
    "\n",
    "##### Steps:\n",
    "1. **In End Routine tab**, when a False Alarm occurs (i.e., `sequence[trials.thisRepN] == 1 and task_kb.keys == 'space'`), subtract one step from the distance counter.\n",
    "2. **Edge Case!** What if `distance_counter` is 0 and a False Alarm occurs? Should it be set to -1? We should handle this case by checking that `distance_counter` is greater than 0 before subtracting 1 from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a274bdce",
   "metadata": {},
   "source": [
    "## User Defines the Reward and Penalty\n",
    "In addition to the first condition, we may want to allow the experimenter to specify rules at the beginning of the session. To enable this, we will make use of the **Experiment info** attributes that can be set in the Experiment Settings window.\n",
    "\n",
    "##### Steps:\n",
    "1. **In Experiment Settings**, add 5 additional fields (and their defaults) to 'Experiment info': `hit_outcome` (1), `fa_outcome` (0), `hits_goal` (20), `num_go_trials` (200), `num_nogo_trials` (100)\n",
    "2. **In Begin Experiment**, replace the assigned values of `num_0s`, `num_1s`, and `distance_goal` with `int(expInfo['num_go_trials'])`, `int(expInfo['num_nogo_trials'])`, and `int(expInfo['hits_goal'])`, respectively.\n",
    "3. **In End Routine**, replace the value to update distance counter with `int(expInfo['hit_outcome'])` and `int(expInfo['fa_outcome'])`.\n",
    "4. **Edge Case!** What happens if the `distance_counter` is less than the `fa_outcome`? `distance_counter` would be negative. We need to handle these cases.\n",
    "\n",
    "**Question:** Let's say that our study consists of 2 group conditions. For one group, a False Alarm moves you 5 steps back. For a second group, a False Alarm moves you 10 steps back. Which group would you expect to False Alarm more (i.e., which group would have their decision criterion more biased towards the noise distribution)?\n",
    "\n",
    "Now let's test our experiment! At the prompt, set `hit_outcome` to 1 and `fa_outcome` to 10. This means that for every hit, the subject moves forward one step. For everay false alarm, the subject moves back 10 steps. \n",
    "\n",
    "As you can see, this flexibility in allowing the user to specify parameters is one of the advantages of taking a more programmatic approach earlier (instead of hard-coding everything)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdc2c50",
   "metadata": {},
   "source": [
    "## Special Reward/Penalty Condition\n",
    "Let's create one special reward/penalty condition where subjects are *returned to the beginning* if they make a False Alarm. The experimenter should be able to specify this conditions by typing \"beginning\" in the `fa_outcome` experiment info field.\n",
    "\n",
    "##### Steps:\n",
    "1. **In End Routine**, in the code block of the if statement that checks for False Alarms, add an additional nested code block that tests for whether the `expInfo['fa_outcome'] == \"beginning\"`. If it does, set `distance_counter` to 0; else, do what was done earlier.\n",
    "2. Since the last step was difficult to articulate in words, I'll just explain the full code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efea94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update distance counter if trial \n",
    "if sequence[trials.thisRepN] == 0 and task_kb.keys == 'space':      # test for HIT\n",
    "    distance_counter = distance_counter + int(expInfo['hit_outcome'])\n",
    "elif sequence[trials.thisRepN] == 1 and task_kb.keys == 'space':    # test for FA\n",
    "    if expInfo['fa_outcome'] == \"beginning\":\n",
    "        distance_counter = 0\n",
    "    else:\n",
    "        if distance_counter >= int(expInfo['fa_outcome']):\n",
    "            distance_counter = distance_counter - int(expInfo['fa_outcome'])\n",
    "        else:\n",
    "            distance_counter = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d772d9",
   "metadata": {},
   "source": [
    "## Embellishments!\n",
    "Now let's add some features to make this experiment feel more gamified*. Here are a couple of ideas:\n",
    "\n",
    "- Add background music that continuously loops. Maybe a song from the Squid Game soundtrack?\n",
    "- \"Game Over\" screen whenever you false alarm. For example, maybe have the doll's eye turn red and screen turn red?\n",
    "- \"Finished\" screen when you complete the experiment. One idea is to have some ominous-sounding text like \"Congratulations on passing the first game. Next game...\" and then show the Squid Game dalgona symbols.\n",
    "- Any other easy to execute ideas?\n",
    "\n",
    "I've curated the stimuli to make these work, but I haven't coded them yet so I don't have instructions.\n",
    "\n",
    "*Note that in a cognitive psychology lab experiment, there's probably no need to \"gamify\" the study. This is just for fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f9831f",
   "metadata": {},
   "source": [
    "## Next Week...\n",
    "We will talk about data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
