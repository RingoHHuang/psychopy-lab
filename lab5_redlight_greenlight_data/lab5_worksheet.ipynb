{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b692fb1c",
   "metadata": {},
   "source": [
    "# Lab 5 - Data!\n",
    "## Collecting Data From the Red Light, Green Light Game \n",
    "\n",
    "To follow along, please download this jupyter notebook file from the Week 5 Lab folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c29335d",
   "metadata": {},
   "source": [
    "## Python Packages\n",
    "When programming, we may often find ourseleves needing a function that is not available in base Python. In these cases, you can turn to Python **packages**, which are open-source software developed by the Python community.\n",
    "\n",
    "Two commonly used packages for data manipulation are `pandas` and `numpy`. We will be using functions from these packages to:\n",
    "\n",
    "    1) record useful data from each trial to a data frame\n",
    "    2) write this data frame to a csv file\n",
    "    3) open up this csv file and wrangle the data\n",
    "    4) create a simple visualization of the data\n",
    "\n",
    "#### Installing Packages\n",
    "To install packages, we can use `pip`. More information about `pip` can be found here: https://packaging.python.org/tutorials/installing-packages/\n",
    "\n",
    "We will use `pip` to install `pandas`. `pip` will also install *dependencies*, or other Python packages, that are needed to run `pandas`. When you run the following command, `numpy` will also be installed because it is a dependency of `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows Users (command prompt):\n",
    "py -m pip install pandas\n",
    "\n",
    "# Mac Users (terminal):\n",
    "python3 -m pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868fba12",
   "metadata": {},
   "source": [
    "## Intro to Numpy and Pandas\n",
    "`numpy` and `pandas` are both very popular packages that are frequently used when we need to manipulate data.\n",
    "\n",
    "#### Importing packages\n",
    "In order to have access to a function during a session, we need to first import the packages. Let's import the `pandas` and `numpy` modules with the following variable names `pd` and `np` as shorthand to access methods in those packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61013ee6",
   "metadata": {},
   "source": [
    "#### The numpy array\n",
    "The `numpy` array is another way to store data. Unlike `lists`, however, `numpy` arrays can only contains data of the same type.\n",
    "\n",
    "What happens here when we create an array vs a list? Print the variables to see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea4a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.array([\"asdf\",1,2,3])\n",
    "\n",
    "#my_list = [\"asdf\",1,2,3]\n",
    "\n",
    "my_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837d6a2",
   "metadata": {},
   "source": [
    "Unlike lists, however, `numpy` arrays can be formatted in both rows and columns. This is helpful when we want to record data in PsychoPy experiments, because we usually want to add a new row of data for each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a8aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3x3 array\n",
    "my_array = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(my_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7d4792",
   "metadata": {},
   "source": [
    "#### The pandas data frame\n",
    "So what if we want to mix data types and still have a matrix-like format? Well, we can use the `pandas` data frame. \n",
    "\n",
    "With the data frame, we can label the columns. One way to build data frames is by using a dictionary. Let's fabricate a data frame that you might get from our Red Light, Green Light game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f30ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'trial_type':['go','nogo','go','go'],'rt': [1.1,0,0,0.8],'resp':['space','NA','NA','space']}\n",
    "\n",
    "data_df = pd.DataFrame(data_dict)\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f29f197",
   "metadata": {},
   "source": [
    "#### Adding trial-by-trial data\n",
    "In our PsychoPy experiment, we will be adding a row to a nested list one trial at a time. Then turn this list to a data frame. Let's simulate how we'll be adding data to our list with each trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the dummy \"trial\" data\n",
    "trial_types = ['go', 'nogo', 'go', 'go', 'go', 'nogo', 'go']\n",
    "rts = [1.1, 0, 1.4, 0, 0.8, 0.7, 1.2, 1.5]\n",
    "resps = [\"space\", \"NA\", \"space\", \"NA\", \"space\", \"space\", \"space\", \"space\"]\n",
    "\n",
    "# Initialize an empty list\n",
    "session_list = list()\n",
    "\n",
    "# Iterate through each \"trial\"\n",
    "for i in range(len(trial_types)):\n",
    "    # Put the data for this trial in a dictionary:\n",
    "    trial_list = [trial_types[i], rts[i], resps[i]]\n",
    "    # Add this trial's dictionary data to the data frame:\n",
    "    session_list.append(trial_list)\n",
    "\n",
    "print(session_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d5f1cc",
   "metadata": {},
   "source": [
    "Now that we have a `session_list` (which is a nested list where each sub-list contains the data from each trial), we can put it in a `pandas` data frame. We would usually put this code somewhere near the end of our PsychoPy experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d18e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the trial\n",
    "session_df = pd.DataFrame(session_list,\n",
    "                         columns = [\"trial_type\", \"rt\", \"resp\"])\n",
    "\n",
    "session_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ebe048",
   "metadata": {},
   "source": [
    "### Write data to a .csv file\n",
    "Finally, we need to output our data frame `session_df` to a .csv file. We need to specify a file name for this method - to create a unique data file, we'll usually include the subject ID in the file name. Let's look at an example with a hypothetical subject #103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_id = 103\n",
    "\n",
    "# to create the full file path, we need to concatenate strings:\n",
    "output_filepath = 'sub-' + str(sub_id) + '_redlight_greenlight.csv' \n",
    "print(output_filepath)\n",
    "# write the session_df data frame object to a csv file:\n",
    "session_df.to_csv(output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cced01",
   "metadata": {},
   "source": [
    "## Creating Custom Data Outputs in Red Light, Green Light\n",
    "After each session, PsychoPy by default outputs a .psydat and .csv data file to a sub-folder called \"data\". These file formats are not designed in a way that is easy to use for data analysis (open up one of the .csv files to see for yourself). Because these default outputs are not formatted in a nice way, we will use `numpy` and `pandas` to create data files that are easier to read and use for our later data analyses.\n",
    "\n",
    "In our data output file, we each row represents one trial. Our goal is to output a data file with 3 columns:\n",
    "1) trial_type (\"go\" or \"nogo\")\n",
    "2) resp (\"space\" or \"NA\")\n",
    "3) rt (reaction time as a float)\n",
    "\n",
    "To follow along, please download **redlight_greenlight_data_class_demo.psyexp** from the Week 5 folder on CCLE.\n",
    "\n",
    "#### Steps:\n",
    "1. Let's create a new code component in the `trial` routine called `log_data`\n",
    "2. In the Begin Experiment tab, we will 1) import modules that we need and 2) initialize empty lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "session_list = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178487e0",
   "metadata": {},
   "source": [
    "3. In the End Routine tab, we need to retrieve the `trial_type`, `resp`, and `rt`. We then put it in a list (trial-level), and then put that trial-level list in the session-level list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626da800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is this a nogo or go trial?\n",
    "if sequence[trials.thisRepN] == 0:\n",
    "    trial_type = \"go\"\n",
    "elif sequence[trials.thisRepN] == 1:\n",
    "    trial_type = \"nogo\"\n",
    "    \n",
    "# Get rt and resp\n",
    "rt = task_kb.rt\n",
    "resp = task_kb.keys\n",
    "\n",
    "# Add this to trial_list, then append trial_list to session_list:\n",
    "trial_list = [trial_type, resp, rt]\n",
    "\n",
    "session_list.append(trial_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95338bbf",
   "metadata": {},
   "source": [
    "4. Create a new routine called `finished` and put it at the end of the Flow timeline. Add a code component called `write_data`. Then write that data frame to an output csv file. This csv file needs to contain the participant ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a311ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put session_list in a data frame\n",
    "session_df = pd.DataFrame(session_list,\n",
    "                         columns = [\"trial_type\", \"resp\", \"rt\"])\n",
    "\n",
    "# Concatenate output file path\n",
    "output_filepath = 'sub-' + expInfo['participant'] + '_redlight_greenlight.csv'\n",
    "\n",
    "# Write data frame to csv file\n",
    "session_df.to_csv(output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff6c1d",
   "metadata": {},
   "source": [
    "We now have a .csv data output after we finish each session of our experiment!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c669efc",
   "metadata": {},
   "source": [
    "## Exploring the Data Output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a8fc76",
   "metadata": {},
   "source": [
    "#### Read the data\n",
    "First, we need to read the .csv file as a `pandas` data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b79ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_df = pd.read_csv('sub-101_redlight_greenlight.csv')\n",
    "\n",
    "session_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d9974",
   "metadata": {},
   "source": [
    "Let's play around with this data frame to see what we can do!\n",
    "\n",
    "See the documentation here: https://pandas.pydata.org/docs/reference/frame.html\n",
    "\n",
    "#### Count the number of \"go\" trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access a column:\n",
    "session_df[\"trial_type\"]\n",
    "\n",
    "# logical array:\n",
    "session_df[\"trial_type\"] == \"go\"\n",
    "\n",
    "# count number of trues in logical array:\n",
    "sum(session_df[\"trial_type\"] == \"go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b700f141",
   "metadata": {},
   "source": [
    "#### Count number of hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b5cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hits logical array is the intersection of these two conditional tests:\n",
    "hits_la = (session_df[\"resp\"] == \"space\") & (session_df[\"trial_type\"] == \"go\")\n",
    "\n",
    "sum(hits_la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c27c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c1f38",
   "metadata": {},
   "source": [
    "#### Use logical indexing to label trials as \"hits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc22feb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# notice how we use hits_la (the logical index of hits):\n",
    "session_df.loc[hits_la, \"sdt_label\"] = \"hit\"\n",
    "\n",
    "session_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a3239",
   "metadata": {},
   "source": [
    "#### Label the other trials as \"hits\", \"false alarms\", \"misses\", \"correct rejections\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_la = (session_df[\"resp\"] == \"space\") & (session_df[\"trial_type\"] == \"go\")\n",
    "fa_la = (session_df[\"resp\"] == \"space\") & (session_df[\"trial_type\"] == \"nogo\")\n",
    "cr_la = (session_df[\"resp\"].isna()) & (session_df[\"trial_type\"] == \"nogo\")\n",
    "miss_la = (session_df[\"resp\"].isna()) & (session_df[\"trial_type\"] == \"go\")\n",
    "\n",
    "\n",
    "sum(miss_la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e65140",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_df[\"resp\"][0:1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
